## Attention (wip)

This repository will house a visualization that will attempt to convey instant enlightenment of how <a href="https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/">Attention</a> works, in the field of artificial intelligence. Obviously I believe this algorithm to be one of the most important developments in the history of deep learning. We can possibly use it to solve, well, everything.

In my mind, one good intuitive visualization can bring about more insight and understanding than long highly paid tutoring / courses.

## What has Attention accomplished?

- [Protein Folding](https://www.nature.com/articles/s41586-021-03819-2)
- [Language](https://arxiv.org/abs/2005.14165)
- [Vision](https://arxiv.org/abs/2010.11929)
- [Image Segmentation](https://arxiv.org/abs/2005.12872)
- [Speech Recognition](https://arxiv.org/abs/2203.15095)
- [Symbolic Mathematics](https://arxiv.org/abs/1912.01412)
- [Music Generation](https://openai.com/blog/musenet/)
- [Theorem Proving](https://arxiv.org/abs/2009.03393)
- [Gene Expression](https://www.nature.com/articles/s41592-021-01252-x)
- [Text to Image](https://openai.com/blog/dall-e/)
- [Text to Video](https://arxiv.org/abs/2111.12417)
- [Code Generation](https://www.deepmind.com/blog/competitive-programming-with-alphacode)
- [Language+](https://arxiv.org/abs/2204.02311)
- [Protein Generation](https://arxiv.org/abs/2004.03497)
- [Multimodal Model](https://arxiv.org/abs/2111.12993)
- [Video Understanding](https://ai.facebook.com/blog/timesformer-a-new-architecture-for-video-understanding/)
- [Heart Disease Classification](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01546-2)
- [Weather Forecasting](https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html)
- [Text to Speech](https://github.com/neonbjb/tortoise-tts)

Will keep adding to this list as time goes on

## Other resources

- [Yannic Kilcher](https://www.youtube.com/watch?v=iDulhoQ2pro)
- [Peter Bloem](http://peterbloem.nl/blog/transformers)
- [Jay Alammar](http://jalammar.github.io/illustrated-transformer/)
- [Sasha Rush](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [Lilian Weng](https://lilianweng.github.io/posts/2018-06-24-attention/)

## Is it all we need?

No one really knows. All I know is, if we were to dethrone attention with a better algorithm, it is over. Part of what motivates me to do some scalable 21st century teaching is the hope maybe someone can find a way to improve on it, or find its replacement. It just takes one discovery!

## Appreciation

Large thanks goes to <a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw">3Blue1Brown</a> for showing us that complex mathematics can be taught with such elegance and potency through visualizations

## Citations

```bibtex
@misc{vaswani2017attention,
    title   = {Attention Is All You Need},
    author  = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year    = {2017},
    eprint  = {1706.03762},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}
```

```bibtex
@article{Bahdanau2015NeuralMT,
    title   = {Neural Machine Translation by Jointly Learning to Align and Translate},
    author  = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    journal = {CoRR},
    year    = {2015},
    volume  = {abs/1409.0473}
}
```

